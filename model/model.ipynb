{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917549c2",
   "metadata": {},
   "source": [
    "# Cursive Handwriting OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f235cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # OpenCV\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from scipy import ndimage\n",
    "# iscrtavanje slika u notebook-u\n",
    "%matplotlib inline\n",
    "# prikaz vecih slika\n",
    "matplotlib.rcParams['figure.figsize'] = 16,12\n",
    "# keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77946836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marija\n",
    "\n",
    "def load_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def display_image(image, color=False):\n",
    "    if color:\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.figure()\n",
    "        plt.imshow(image, 'gray')\n",
    "\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def image_bin(image_gs):                                                    # gs -> gray scale\n",
    "    height, width = image_gs.shape[0:2]                                     # [0,2] uzimamo prve dve vrednosti -> visinu i sirinu\n",
    "    \n",
    "    image_bin = cv2.adaptiveThreshold(image_gs, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 35, 10)\n",
    "    return image_bin\n",
    "\n",
    "def invert(image):\n",
    "    return 255-image\n",
    "\n",
    "def dilate(image):                                                          # prosiruje bele delove slike\n",
    "    kernel = np.ones((3, 3))                                                # strukturni element 3x3 blok\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def erode(image):                                                           # smannjuje bele delove slike\n",
    "    kernel = np.ones((3, 3))                                                # strukturni element 3x3 blok\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def open(image):                                                            #otvaranje = erozija + dilacija\n",
    "    return erode(dilate(image))                                             #uklanjanje šuma erozijom i vraćanje originalnog oblika dilacijom\n",
    "\n",
    "def close(image):                                                           #zatvaranje = dilacija + erozija,\n",
    "    return dilate(erode(image))                                             #zatvaranje sitnih otvora među belim pikselima\n",
    "\n",
    "def resize_region(region):\n",
    "    return cv2.resize(region, (36, 36), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def matrix_to_vector(image):                                                #pretvara sliku u vektoru\n",
    "    return image.flatten()\n",
    "\n",
    "def scale_to_range(image):                                                  #skalira boje sa opsega [0, 255] na [0, 1]   \n",
    "    return image/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01263308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nenad\n",
    "# Ćelija u kojoj se nalazi kod koji se koristi za spajanje ROI koji se nalaze na trening podacima\n",
    "\n",
    "def select_roi_training(image_orig, image_bin):\n",
    "    contours, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    regions_array = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        region = image_bin[y:y+h+1, x:x+w+1]\n",
    "        regions_array.append([resize_region(region), (x, y, w, h)])\n",
    "\n",
    "    # Konture koje sadrze kukice\n",
    "    connected_regions = [] \n",
    "    # Prolazimo kroz niz i proveravamo da li u ostatku niza postoji neki region iznad ili ispod trenutnog i ako \n",
    "    # postoji takav region, pravimo jedan veci region oko njih i dodajemo ga\n",
    "    for region1, (x1, y1, w1, h1) in regions_array:\n",
    "        for _region2, (x2, y2, w2, h2) in regions_array:\n",
    "            # Provera da li je isti region\n",
    "            if (x1, y1, w1, h1) == (x2, y2, w2, h2):\n",
    "                continue\n",
    "            mid_x2 = x2 + w2 // 2\n",
    "\n",
    "            # Provera da li je region kvacica\n",
    "            if (y1 >= y2 or y1 <= y2) and mid_x2 >= x1 and mid_x2 <= x1 + w1:\n",
    "                x3, y3, w3, h3 = min(x1, x2), y2, max(w1, w2), h1+(y1-y2)\n",
    "                region3 = image_bin[y3:y3+h3+1, x3:x3+w3+1]\n",
    "                connected_regions.append([resize_region(region3), (x3, y3, w3, h3)])\n",
    "\n",
    "    # Sad cemo proci kroz niz regions_array i videti da li se centar tih objekata nalazi unutar \n",
    "    # nekog veceg koji je u connected_regions\n",
    "    # Filtiramo regione tako da na primer za slovo ž sad imamo 2 regiona u regions_array i 1 veci\n",
    "    # region u connected_regions\n",
    "    # Ona 2 regiona ne dodajemo u filtrirane regione dok cemo 1 veci region dodati kasnije\n",
    "    # Ako se nalazi, preskacemo taj objekat, a ako ne onda ga dodajemo u nov niz\n",
    "    filtered_regions = []\n",
    "    for region1, (x1, y1, w1, h1) in regions_array:\n",
    "        mid_x1 = x1 + w1 // 2\n",
    "        mid_y1 = y1 + h1 // 2\n",
    "        is_in = False\n",
    "        for _region2, (x2, y2, w2, h2) in connected_regions:\n",
    "            if mid_x1 >= x2 and mid_x1 <= x2 + w2 and mid_y1 >= y2 and mid_y1 <= y2 + h2:\n",
    "                is_in = True\n",
    "        if not is_in:\n",
    "            filtered_regions.append([region1, (x1, y1, w1, h1)])\n",
    "    \n",
    "    # Dodajemo i one velike regione u kojem su slova sa kukicama\n",
    "    filtered_regions += connected_regions\n",
    "\n",
    "    # Iscrtavamo sve te regione\n",
    "    for _, (x, y, w, h) in filtered_regions:\n",
    "        cv2.rectangle(image_orig, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "    # Sortiramo niz u kojem su elementi [region, koordinate] po x koordinati\n",
    "    filtered_regions = sorted(filtered_regions, key=lambda x: x[1][0])\n",
    "    sorted_regions = [region[0] for region in filtered_regions]\n",
    "\n",
    "    return image_orig, sorted_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1982eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marija\n",
    "\n",
    "def create_ann(output_size):                                        #pravljenje neuronske mreze\n",
    "    ann = Sequential()\n",
    "    ann.add(Flatten(input_shape=(64, 64, 1)))  # Dodaj Flatten sloj\n",
    "    ann.add(Dense(128, input_dim=1296, activation='sigmoid'))       #36x36 -> ulazni sloj ima 1296 neurona \n",
    "    ann.add(Dense(output_size, activation='sigmoid'))\n",
    "\n",
    "    ann.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return ann\n",
    "\n",
    "def prepare_for_ann(regions):\n",
    "    ready_for_ann = []\n",
    "    for region in regions:\n",
    "        scale = scale_to_range(region)\n",
    "        ready_for_ann.append(matrix_to_vector(scale))\n",
    "    return ready_for_ann\n",
    "\n",
    "def convert_output(alphabet):                                       #u sustini a je [1 0 0 ... ], b je [0, 1, 0..]\n",
    "    nn_outputs = []\n",
    "    for index in range(len(alphabet)):\n",
    "        output = np.zeros(len(alphabet))                            #napravimo niz nula\n",
    "        output[index] = 1                                           #na redni broj slova u alfabetu ide 1\n",
    "        nn_outputs.append(output)\n",
    "    return np.array(nn_outputs)\n",
    "\n",
    "def train_ann(ann, train, validation, epochs):\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=12,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTraining started...\")\n",
    "    history = ann.fit(train, epochs=epochs, verbose=1, validation_data=validation, callbacks=callbacks)\n",
    "    print(\"\\nTraining completed...\")\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.show()\n",
    "    return ann\n",
    "\n",
    "def winner(output):                                                                    # odredjuje pobednicki neuron, onaj  neuron\n",
    "    return max(enumerate(output), key=lambda x: x[1])[0]                               # cija je aktivaciona vrednost najveca\n",
    "\n",
    "def display_result_with_spaces(outputs, alphabet, k_means):                                                          \n",
    "    w_space_group = max(enumerate(k_means.cluster_centers_), key=lambda x: x[1])[0]    # odredjuje rastojanje izmedju reci (max)\n",
    "                                                                                       # enumerate daje parove\n",
    "    result = alphabet[winner(outputs[0])]\n",
    "                                                                                                                        \n",
    "    for idx, output in enumerate(outputs[1:, :]):\n",
    "        if k_means.labels_[idx] == w_space_group:\n",
    "            result += ' '\n",
    "        result += alphabet[winner(output)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bccfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nenad\n",
    "# Ćelija u kojoj se nalazi algoritam za rotiranje slike\n",
    "def rotate_image_to_normal(image, image_grayscale):\n",
    "    image_edges = cv2.Canny(image_grayscale, 100, 100, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(image_edges, 1, math.pi / 180.0, 100, maxLineGap=5)\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    for [[x1, y1, x2, y2]] in lines:\n",
    "        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    median_angle = np.median()\n",
    "    image_rotated = ndimage.rotate(image, median_angle)\n",
    "\n",
    "    return image_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482cc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marija\n",
    "\n",
    "def order_points(pts):                                                                                 # pomoćna funkcija, biće potrebna za correct_skewed_image\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")                                                           \n",
    "\n",
    "    s = pts.sum(axis=1)                                                                               \n",
    "    rect[0] = pts[np.argmin(s)]                                                                         # top-left (najmanji zbir x + y)\n",
    "    rect[2] = pts[np.argmax(s)]                                                                         # bottom-right (najveći zbir x + y)\n",
    "\n",
    "    diff = np.diff(pts, axis=1)                                                                        \n",
    "    rect[1] = pts[np.argmin(diff)]                                                                      # top-right (najmanja razlika x - y)\n",
    "    rect[3] = pts[np.argmax(diff)]                                                                      # bottom-left (najveća razlika x - y)\n",
    "\n",
    "    return rect\n",
    "\n",
    "def image_gray(image):                                                                                 # helper funkcija za konverziju u grayscale\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def correct_skewed_image(image):                                                                       # ispravlja slike slikane pod nekim uglom\n",
    "    gray = image_gray(image)                                                                           \n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)                                                         # blurujem da bih smanjila šum i lakše prepoznala ivice\n",
    "    edges = cv2.Canny(blurred, 50, 150)                                                                 # detekcija ivica pomoću Canny algoritma\n",
    "\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)                      \n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)                                     # sortira konture od najveće do najmanje površine\n",
    "\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)                  # uprošćava se kontura\n",
    "        if len(approx) == 4:\n",
    "            screen_cnt = approx\n",
    "            break\n",
    "    else:\n",
    "        return image                                                                                    # ako ne nađe konture, vrati original\n",
    "\n",
    "    rect = order_points(screen_cnt.reshape(4, 2))                                                       # uredimo tačke\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    width_a = np.linalg.norm(br - bl)                                                                   # donja ivica\n",
    "    width_b = np.linalg.norm(tr - tl)                                                                   # gornja ivica\n",
    "    max_width = max(int(width_a), int(width_b))                                                         # širina ispravljene slike\n",
    "\n",
    "    height_a = np.linalg.norm(tr - br)                                                                  \n",
    "    height_b = np.linalg.norm(tl - bl)                                                                  \n",
    "    max_height = max(int(height_a), int(height_b))                                                      # visina ispravljene slike\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],                                                                                          # gornji levi ugao\n",
    "        [max_width - 1, 0],                                                                             # gornji desni\n",
    "        [max_width - 1, max_height - 1],                                                                # donji desni\n",
    "        [0, max_height - 1]                                                                             # donji levi\n",
    "    ], dtype=\"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)                                                          \n",
    "    warped = cv2.warpPerspective(image, M, (max_width, max_height))                                    # slika se ispravlja\n",
    "\n",
    "    return warped                                                                                       # vraćamo ispravljenu sliku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e9fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nenad\n",
    "# PRVA CELIJA ZA Z2V5 \n",
    "# Ideja za resenje:\n",
    "# Priprema za algoritam:\n",
    "# 1. Neophodno je uraditi selekciju ROI tako da se upamte centri svih kontura u jednom nizu kao i pravougaonici oko kontura\n",
    "# (2.) Eventualno se mogu upamtiti i visine svih karaktera zbog koraka 2 u algoritmu, to ipak nije uradjeno\n",
    "# Obrada red po red po sledecim pravilima:\n",
    "# 1. Uzeti minimalnu y-vrednost centra karaktera u samom nizu centara i izdvojiti ga u poseban niz i obrisati iz trenutnog\n",
    "# 2. Proci kroz ostatak niza i proveriti da li postoje karakteri sa slicnom y-vrednost centra (y-centar + (visina-karaktera / 2 ili prosto 14 ili prosecna-visina-svih-karaktera / 2)) i dodati ih u poseban niz i obrisati iz trenutnog\n",
    "# 3. Sortirati poseban niz po x-vrednosti centara i sracunati udaljenosti izmedju svaka 2 karaktera kako bismo mogli uraditi KMeans nad ovim redom\n",
    "# 4. Prikazemo rezultat samo tog jednog reda sa razmacima i dodamo '\\n' na kraj rezultata\n",
    "# 5. Ponavljamo korake 1-4 sve dok ne dobijemo prazan red centara\n",
    "# Imas claude i gpt odgovor na ovo :3\n",
    "\n",
    "# Ideja za verziju 2\n",
    "# Implementirati isto kao i sto je radjeno sa razmacima ali upotrebom DBSCAN algoritma\n",
    "\n",
    "# Za detaljno objasnjenje posetiti sajt koji je preporucen za Non-Maximum Suppresion\n",
    "# https://pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/\n",
    "\n",
    "def non_max_suppression_slow(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# initialize the list of picked indexes\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list, add the index\n",
    "\t\t# value to the list of picked indexes, then initialize\n",
    "\t\t# the suppression list (i.e. indexes that will be deleted)\n",
    "\t\t# using the last index\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\tsuppress = [last]\n",
    "\t\t\t\t# loop over all indexes in the indexes list\n",
    "\t\tfor pos in range(0, last):\n",
    "\t\t\t# grab the current index\n",
    "\t\t\tj = idxs[pos]\n",
    "\t\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t\t# for the end of the bounding box\n",
    "\t\t\txx1 = max(x1[i], x1[j])\n",
    "\t\t\tyy1 = max(y1[i], y1[j])\n",
    "\t\t\txx2 = min(x2[i], x2[j])\n",
    "\t\t\tyy2 = min(y2[i], y2[j])\n",
    "\t\t\t# compute the width and height of the bounding box\n",
    "\t\t\tw = max(0, xx2 - xx1 + 1)\n",
    "\t\t\th = max(0, yy2 - yy1 + 1)\n",
    "\t\t\t# compute the ratio of overlap between the computed\n",
    "\t\t\t# bounding box and the bounding box in the area list\n",
    "\t\t\toverlap = float(w * h) / area[j]\n",
    "\t\t\t# if there is sufficient overlap, suppress the\n",
    "\t\t\t# current bounding box\n",
    "\t\t\tif overlap > overlapThresh:\n",
    "\t\t\t\tsuppress.append(pos)\n",
    "\t\t# delete all indexes from the index list that are in the\n",
    "\t\t# suppression list\n",
    "\t\tidxs = np.delete(idxs, suppress)\n",
    "\t# return only the bounding boxes that were picked\n",
    "\treturn boxes[pick]\n",
    "\n",
    "def select_roi_test(image_orig, image_bin):\n",
    "\tcontours, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tsorted_regions = [] # lista sortiranih regiona po X osi\n",
    "\tregions_array = []\n",
    "\tfor contour in contours:\n",
    "\t\tx, y, w, h = cv2.boundingRect(contour) # koordinate i velicina granicnog pravougaonika\n",
    "\t\t# kopirati [y:y+h+1, x:x+w+1] sa binarne slike i smestiti u novu sliku\n",
    "\t\t# oznaciti region pravougaonikom na originalnoj slici sa rectangle funkcijom\n",
    "\t\tregion = image_bin[y:y+h+1, x:x+w+1]\n",
    "\t\tregions_array.append([resize_region(region), (x, y, w, h)])\n",
    "\n",
    "\t#\n",
    "\t#\n",
    "\t# ---------- DEO KOJI JE ISTI KAO ONAJ ZA KVACICE ----------\n",
    "\t#\n",
    "\t#\n",
    "\t# Konture koje sadrze kukice\n",
    "\tconnected_regions = [] \n",
    "\t# Prolazimo kroz niz i proveravamo da li u ostatku niza postoji neki region iznad ili ispod trenutnog i ako \n",
    "\t# postoji takav region, pravimo jedan veci region oko njih i dodajemo ga\n",
    "\tfor region1, (x1, y1, w1, h1) in regions_array:\n",
    "\t\tfor _region2, (x2, y2, w2, h2) in regions_array:\n",
    "\t\t\t# Provera da li je isti region\n",
    "\t\t\tif (x1, y1, w1, h1) == (x2, y2, w2, h2):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tmid_x2 = x2 + w2 // 2\n",
    "\n",
    "            # Provera da li je region kvacica\n",
    "\t\t\tif (y1 >= y2 or y1 <= y2) and mid_x2 >= x1 and mid_x2 <= x1 + w1:\n",
    "\t\t\t\tx3, y3, w3, h3 = min(x1, x2), y2, max(w1, w2), h1+(y1-y2)\n",
    "\t\t\t\tregion3 = image_bin[y3:y3+h3+1, x3:x3+w3+1]\n",
    "\t\t\t\tconnected_regions.append([resize_region(region3), (x3, y3, w3, h3)])\n",
    "\n",
    "\t# Sad cemo proci kroz niz regions_array i videti da li se centar tih objekata nalazi unutar \n",
    "\t# nekog veceg koji je u connected_regions\n",
    "\t# Filtiramo regione tako da na primer za slovo ž sad imamo 2 regiona u regions_array i 1 veci\n",
    "\t# region u connected_regions\n",
    "\t# Ona 2 regiona ne dodajemo u filtrirane regione dok cemo 1 veci region dodati kasnije\n",
    "\t# Ako se nalazi, preskacemo taj objekat, a ako ne onda ga dodajemo u nov niz\n",
    "\tfiltered_regions = []\n",
    "\tfor region1, (x1, y1, w1, h1) in regions_array:\n",
    "\t\tmid_x1 = x1 + w1 // 2\n",
    "\t\tmid_y1 = y1 + h1 // 2\n",
    "\t\tis_in = False\n",
    "\t\tfor _region2, (x2, y2, w2, h2) in connected_regions:\n",
    "\t\t\tif mid_x1 >= x2 and mid_x1 <= x2 + w2 and mid_y1 >= y2 and mid_y1 <= y2 + h2:\n",
    "\t\t\t\tis_in = True\n",
    "\t\tif not is_in:\n",
    "\t\t\tfiltered_regions.append([region1, (x1, y1, w1, h1)])\n",
    "    \n",
    "    # Dodajemo i one velike regione u kojem su slova sa kukicama\n",
    "\tfiltered_regions += connected_regions\n",
    "\t#\n",
    "\t#\n",
    "\t# ---------- KRAJ DELA KOJI JE ISTI KAO ONAJ ZA KVACICE ----------\n",
    "\t#\n",
    "\t#\n",
    "\n",
    "\tregions_array = filtered_regions\n",
    "\t# Pripremamo podatke za NMS funkciju jer ona uzima podatke u obliku [x1, y1, x2, y2] (gornje levo teme i donje desno teme pravougaonika)\n",
    "\t# Dok mi radimo ovde samo sa (y1, x1) <- dovoljno je znati samo gornje levo teme jer znamo da su svi auti dimenzija 100x40 (width x height)\n",
    "\tboundingBoxes = np.zeros((len(regions_array), 4))\n",
    "\tfor i in range(len(regions_array)):\n",
    "\t\tx, y, w, h = regions_array[i][1]\n",
    "\t\tboundingBoxes[i] = [x, y, x + w, y + h]\n",
    "\n",
    "\t# Primenjujemo NMS\n",
    "\tboundingBoxes = non_max_suppression_slow(boundingBoxes, 0.3)\n",
    "\t# Vracamo podatke u oblik [x, y, w, h]\n",
    "\tboundingBoxes = [[x1, y1, x2 - x1, y2 - y1] for (x1, y1, x2, y2) in boundingBoxes]\n",
    "\n",
    "\t# Pravimo skup od tih podataka, u skupu se nalaze samo x vrednosti koordinata\n",
    "\tbounding_box_set = set(box[0] for box in boundingBoxes)\n",
    "\t# Filtriramo regions_array kako bismo samo zadrzali elemente koje nam je NMS vratio\n",
    "\tfiltered_regions = [\n",
    "        item for item in regions_array \n",
    "        if item[1][0] in bounding_box_set\n",
    "    ]\n",
    "\n",
    "\t# Iscrtavamo pravougaonike oko svakog od filtriranih regiona\n",
    "\tfor _, (x,y,w,h) in filtered_regions:\n",
    "\t\tcv2.rectangle(image_orig, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\t# Sortiramo filtrirane regione\n",
    "\tfiltered_regions = sorted(filtered_regions, key=lambda x: x[1][0])\n",
    "\n",
    "\t# Izdvajamo same regione\n",
    "\tsorted_regions = [region[0] for region in filtered_regions]\n",
    "\n",
    "\t# Izdvajamo centre regione u oblik (x_centar, y_centar)\n",
    "\tregions_centers = [] # lista centara samih karaktera\n",
    "\tregions_centers = [(region[1][0] + region[1][2] // 2, region[1][1] + region[1][3] // 2) for region in filtered_regions]\n",
    "\t\n",
    "\t# Izdvajamo [x, y, w, h] iz regiona\n",
    "\tsorted_rectangles = [region[1] for region in filtered_regions]\n",
    "\treturn image_orig, sorted_regions, regions_centers, sorted_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b6fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set already exists!\n"
     ]
    }
   ],
   "source": [
    "# Nenad\n",
    "# Ćelija koja se koristi za kreiranje validacionih podataka na osnovu trening skupa\n",
    "\n",
    "def pick_random_files(directory, count=3):\n",
    "    all_items = os.listdir(directory)\n",
    "    files = [f for f in all_items if os.path.isfile(os.path.join(directory, f))]\n",
    "    \n",
    "    # Pick random files\n",
    "    if len(files) >= count:\n",
    "        random_files = random.sample(files, count)\n",
    "        return random_files\n",
    "    else:\n",
    "        return files\n",
    "    \n",
    "def create_validation_folder(training_folder, validation_folder):\n",
    "    for character_name in os.listdir(training_folder):\n",
    "        # Ako već postoji validacioni folder, onda nastavljamo na sledeći karakter\n",
    "        if character_name in os.listdir(validation_folder):\n",
    "            continue\n",
    "        \n",
    "        current_images_folder = training_folder + character_name + '/'\n",
    "        new_validation_folder = validation_folder + character_name\n",
    "        os.makedirs(new_validation_folder)  \n",
    "        new_validation_folder += '/'\n",
    "\n",
    "        files = pick_random_files(current_images_folder, count=3)\n",
    "        for file in files:\n",
    "                source_path = os.path.join(current_images_folder, file)\n",
    "                destination_path = os.path.join(new_validation_folder, file)\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "\n",
    "if 'val' not in os.listdir('../data/'):\n",
    "    os.makedirs('../data/val')\n",
    "    validation_folder = '../data/val/'\n",
    "    training_folder = '../data/train/'\n",
    "    create_validation_folder(training_folder, validation_folder)\n",
    "    print(\"Succesfully created validation set!\")\n",
    "else:\n",
    "    print(\"Validation set already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50927eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nenad\n",
    "# Sad ide pravi test :)\n",
    "\n",
    "def extract_text(image, model_nn, alphabet):\n",
    "    # Ovde ce biti rezultat\n",
    "    test_result = ''\n",
    "    # Ucitamo sliku\n",
    "    test_color = image.copy()\n",
    "    test = image_bin(image_gray(test_color))\n",
    "    test_bin = dilate(erode(test))\n",
    "\n",
    "    # Oznacavamo ROI i prikazujemo sliku\n",
    "    selected_test, sorted_regions, regions_centers, sorted_rectangles = select_roi_test(test_color.copy(), test_bin)\n",
    "    display_image(selected_test)\n",
    "\n",
    "    # Pravimo temp jer cemo iz njega u algoritmu brisati elemente \n",
    "    sorted_regions_temp = sorted_regions.copy()\n",
    "\n",
    "    while len(regions_centers) > 0:\n",
    "        # 1. Uzeti minimalnu y-vrednost centra karaktera u samom nizu centara i izdvojiti ga u poseban niz i obrisati iz trenutnog\n",
    "        minv = min(regions_centers, key=lambda x: x[1])\n",
    "        # Nabavljamo indeks minimalnog kako bismo znali sa kog indeksa brisemo u drugim nizovima\n",
    "        minv_ind = regions_centers.index(minv)\n",
    "\n",
    "        simillar_center = [regions_centers[minv_ind]]\n",
    "        sorted_regions_row = [sorted_regions_temp[minv_ind]]\n",
    "        sorted_rectangles_row = [sorted_rectangles[minv_ind]]\n",
    "\n",
    "        # Brisanje elementa iz nizova\n",
    "        regions_centers.remove(minv)\n",
    "        del sorted_regions_temp[minv_ind]\n",
    "        del sorted_rectangles[minv_ind]\n",
    "\n",
    "        # 2. Proci kroz ostatak niza i proveriti da li postoje karakteri sa slicnom y-vrednost centra (y-centar + (visina-karaktera / 2 ili prosto 14 ili prosecna-visina-svih-karaktera / 2)) \n",
    "        # i dodati ih u posebne nizove i obrisati iz trenutnih nizova\n",
    "        simillar_center += [x for x in regions_centers if x[1] >= minv[1] - 14 and x[1] <= minv[1] + 14]\n",
    "        for x in simillar_center:\n",
    "            if x in regions_centers:\n",
    "                ind = regions_centers.index(x)\n",
    "                regions_centers.remove(x)\n",
    "                sorted_regions_row += [sorted_regions_temp[ind]]\n",
    "                sorted_rectangles_row += [sorted_rectangles[ind]]\n",
    "                del sorted_regions_temp[ind]\n",
    "                del sorted_rectangles[ind]\n",
    "\n",
    "        # Korisceno da vidim da li sve radi kako sam zeleo :)\n",
    "        #print(len(regions_centers), len(sorted_regions_temp), len(sorted_rectangles))\n",
    "        #print(len(simillar_center), len(sorted_regions_row), len(sorted_rectangles_row))\n",
    "\n",
    "        # 3. Sortirati poseban niz po x-vrednosti centara i sracunati udaljenosti izmedju svaka 2 karaktera kako bismo mogli uraditi KMeans nad ovim redom\n",
    "        # Spajamo regione i centre u jedan niz\n",
    "        sorted_regions_and_centers = []\n",
    "        for i in range(len(sorted_regions_row)):\n",
    "            sorted_regions_and_centers += [[sorted_regions_row[i], simillar_center[i]]]\n",
    "\n",
    "        # Sortiramo niz po x vrednosti i izvlacimo regione i centre u poseban niz\n",
    "        # Ovaj korak je bio potreban jer nisam bio siguran u to da li ce elementi ocuvati sortiranost iz prethodnih koraka\n",
    "        sorted_regions_and_centers = sorted(sorted_regions_and_centers, key=lambda x: x[1][0])\n",
    "        sorted_regions_row = [region[0] for region in sorted_regions_and_centers]\n",
    "        sorted_centers_row = [region[1] for region in sorted_regions_and_centers]\n",
    "\n",
    "        # Racunamo distance i primenjujemo KMeans\n",
    "        region_distances = []\n",
    "        for index in range(0, len(sorted_rectangles_row) - 1):\n",
    "            current = sorted_rectangles_row[index]\n",
    "            next_rect = sorted_rectangles_row[index + 1]\n",
    "            distance = next_rect[0] - (current[0] + current[2]) # x_next - (x_current + w_current)\n",
    "            region_distances.append(distance)\n",
    "\n",
    "        region_distances = np.array(region_distances).reshape(len(region_distances), 1)\n",
    "        k_means = KMeans(n_clusters=2, n_init=10)\n",
    "        k_means.fit(region_distances)\n",
    "\n",
    "        # 4. Prikazemo rezultat samo tog jednog reda sa razmacima i dodamo '\\n' na kraj rezultata\n",
    "        test_inputs = prepare_for_ann(sorted_regions_row)\n",
    "        result = model_nn.predict(np.array(test_inputs, np.float32))\n",
    "        test_result += display_result_with_spaces(result, alphabet, k_means)\n",
    "        test_result += '\\n'\n",
    "        # 5. Ponavljamo korake 1-4 sve dok ne dobijemo prazan red centara\n",
    "\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11fe0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11102 images belonging to 26 classes.\n",
      "Found 78 images belonging to 26 classes.\n",
      "\n",
      "Training started...\n",
      "Epoch 1/100\n",
      "231/694 [========>.....................] - ETA: 55s - loss: 3.2799 - accuracy: 0.0398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m\n\u001b[0;32m     33\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m validation_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/val/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m ann \u001b[38;5;241m=\u001b[39m create_ann(output_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(alphabet)))\n\u001b[1;32m---> 42\u001b[0m ann \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ann\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mtrain_ann\u001b[1;34m(ann, train, validation, epochs)\u001b[0m\n\u001b[0;32m     32\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     EarlyStopping(\n\u001b[0;32m     34\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m ]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining completed...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32md:\\Projects\\Cursive-Handwriting-OCR\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Nenad\n",
    "# Ideja je da folderi se nazivaju po indeksima karaktera koji su u nizu\n",
    "# Primer: Velika slova B se nalaze u folderu 01, što je indeks tog karaktera u alfabetu\n",
    "# Kako se budu dodavali karakteri ići će ovako redom:\n",
    "# 1. Velika slova engleske latinice\n",
    "# 2. Mala slova engleske latinice\n",
    "# 3. Velika slova Č, Ć, Đ, Ž i Š \n",
    "# 4. Mala slova č, ć, đ, ž i š\n",
    "# 5. Velika slova ćirilice\n",
    "# 6. Mala slova ćirilice\n",
    "# 7. Cifre\n",
    "# 8. Znakovi interpunkcije\n",
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "            ]\n",
    "\n",
    "alphabet_labels = [ '00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '0A', '0B', '0C',\n",
    "                    '0D', '0E', '0F', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19'\n",
    "                  ]\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=4)\n",
    "validation_datagen = ImageDataGenerator(rescale=None) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../data/train/',\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(64, 64),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Bice korisceno kad budemo osmislili skup podataka\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '../data/val/',\n",
    "    batch_size=16,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(64, 64),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "ann = create_ann(output_size=(len(alphabet)))\n",
    "ann = train_ann(ann, train_generator, validation_generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1aa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc10f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
